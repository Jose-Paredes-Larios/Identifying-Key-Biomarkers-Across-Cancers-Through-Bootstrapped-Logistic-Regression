{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f70ec69-3252-4eac-9e1e-9d61ae141059",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "### COSC 410B: Spring 2025, Colgate University\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c271bd7-2315-4245-bbba-36a71663ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data=pd.read_csv(\"geneExpressionDataKidney.csv\")\n",
    "target=data[\"label\"]\n",
    "features=data.drop(columns=[\"label\",\"sample_id\"])\n",
    "trainSet, testSet, trainClasses, testClasses=train_test_split(features, target, test_size=0.2, stratify=target, random_state=111)\n",
    "\n",
    "def trainEvaluateModel(model, parameters, varianceThreshold=0.01, topGenesToKeep=1000):\n",
    "    variance=VarianceThreshold(varianceThreshold)#There are several ways to conduct feature selection through sklearn, which have been documented here: https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "    topGenes=SelectKBest(f_classif, k=topGenesToKeep)\n",
    "    pipe=Pipeline([(\"log1p\", FunctionTransformer(np.log1p, validate=False)),(\"varianceFilter\",variance),(\"scaler\", StandardScaler()),(\"topKFeatures\",topGenes),(\"model\",model)])#sklearn pipelines makes feature selection convenient. We learned about them here: https://www.geeksforgeeks.org/what-is-exactly-sklearnpipelinepipeline/\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=111)#We have to call StratifiedKFold() here instead of just doing cv=5 in GridSearchCV() to ensure reproducibility, shuffling, and stratification \n",
    "    gridSearch=GridSearchCV(estimator=pipe, param_grid=parameters, scoring='neg_brier_score', cv=5, n_jobs=-1)\n",
    "    gridSearch.fit(trainSet, trainClasses)#Hyperparameter tuning\n",
    "    bestModel=gridSearch.best_estimator_\n",
    "\n",
    "    #Evaluating Predicted Probabilities\n",
    "    probabilities=bestModel.predict_proba(testSet)[:, 1]#Gathering the probabilities assigned to each sample\n",
    "    print(\"Performance on the Test Set:\")\n",
    "    print(f\"Brier Score: {brier_score_loss(testClasses, probabilities)}\")\n",
    "    print(f\"Cross-entropy Loss: {log_loss(testClasses, probabilities)}\")\n",
    "\n",
    "    #Evaluating Predicted Labels\n",
    "    testPredictions=(probabilities >= 0.5).astype(int)#Converting the probabilities into labels with a threshold of 0.5\n",
    "    print(f\"Accuracy: {accuracy_score(testClasses, testPredictions)}\")\n",
    "    print(f\"Precision: {precision_score(testClasses, testPredictions)}\")\n",
    "    print(f\"Recall: {recall_score(testClasses, testPredictions)}\")\n",
    "    print(f\"F1 Score: {f1_score(testClasses, testPredictions)}\\n\")\n",
    "\n",
    "    #Interpreting the Model (COMMENT THIS OUT IF NOT EVALUATING A LINEAR MODEL)\n",
    "    print(\"The Top Genes that Influence the Model's Predictions:\")\n",
    "    weights=bestModel.named_steps[\"model\"].coef_[0]#Extract the model's weights for the top features (the only weights it has since it was only trained on the top features). The \"bestModel.named_steps[\"X\"]\" notation is just accessing the X step of the pipeline\n",
    "    unfilteredVarianceFeatures=features.columns[bestModel.named_steps[\"varianceFilter\"].get_support()]#Extract the top features the model was trained on\n",
    "    topFeatures=unfilteredVarianceFeatures[bestModel.named_steps[\"topKFeatures\"].get_support()]\n",
    "    topWeights=pd.DataFrame({\"Gene\": topFeatures, \"Weight\": weights})\n",
    "    topWeights[\"Absolute Weight\"]=topWeights[\"Weight\"].abs()\n",
    "    topWeights=topWeights.sort_values(\"Absolute Weight\", ascending=False)#Sort the data frame by the absolute weight column so that the most influential features come first\n",
    "    print(topWeights.head(10).to_string(index=False))#Print out the top ten most influential features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ece39f-70fd-4a11-9770-9a8522d26e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss, log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from sklearn.utils import resample\n",
    "\n",
    "data=pd.read_csv(\"geneExpressionDataBreast.csv\")\n",
    "target=data[\"label\"]\n",
    "features=data.drop(columns=[\"label\",\"sample_id\"])\n",
    "trainSet, testSet, trainClasses, testClasses=train_test_split(features, target, test_size=0.2, stratify=target, random_state=111)\n",
    "\n",
    "def retrieveTopGenes(model, parameters, trainingSet, trainingClasses, varianceThreshold=0.01, topGenesToKeep=1000):\n",
    "    variance=VarianceThreshold(varianceThreshold)#There are several ways to conduct feature selection through sklearn, which have been documented here: https://scikit-learn.org/stable/modules/feature_selection.html\n",
    "    topGenes=SelectKBest(f_classif, k=topGenesToKeep)\n",
    "    pipe=Pipeline([(\"log1p\", FunctionTransformer(np.log1p, validate=False)),(\"varianceFilter\",variance),(\"scaler\", StandardScaler()),(\"topKFeatures\",topGenes),(\"model\",model)])#sklearn pipelines makes feature selection convenient. We learned about them here: https://www.geeksforgeeks.org/what-is-exactly-sklearnpipelinepipeline/\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=111)#We have to call StratifiedKFold() here instead of just doing cv=5 in GridSearchCV() to ensure reproducibility, shuffling, and stratification \n",
    "    gridSearch=GridSearchCV(estimator=pipe, param_grid=parameters, scoring='neg_brier_score', cv=cv, n_jobs=-1)\n",
    "    gridSearch.fit(trainingSet, trainingClasses)#Hyperparameter tuning\n",
    "    bestModel=gridSearch.best_estimator_\n",
    "    \n",
    "    probabilities=bestModel.predict_proba(testSet)[:, 1]#Gathering the probabilities assigned to each sample\n",
    "    predictions=(probabilities >= 0.5).astype(int)#Converting the probabilities into labels with a threshold of 0.5  \n",
    "    metrics={\"accuracy\": accuracy_score(testClasses, predictions), \"precision\": precision_score(testClasses, predictions), \"recall\": recall_score(testClasses, predictions), \"f1\": f1_score(testClasses, predictions)}\n",
    " \n",
    "    weights=bestModel.named_steps[\"model\"].coef_[0]#Extract the model's weights for the top features (the only weights it has since it was only trained on the top features). The \"bestModel.named_steps[\"X\"]\" notation is just accessing the X step of the pipeline\n",
    "    unfilteredVarianceFeatures=trainingSet.columns[bestModel.named_steps[\"varianceFilter\"].get_support()]#Extract the top features the model was trained on\n",
    "    topFeatures=unfilteredVarianceFeatures[bestModel.named_steps[\"topKFeatures\"].get_support()]\n",
    "    topWeights=pd.DataFrame({\"Gene\": topFeatures, \"Weight\": weights})\n",
    "    topWeights[\"Absolute Weight\"]=topWeights[\"Weight\"].abs()\n",
    "    topWeights=topWeights.sort_values(\"Absolute Weight\", ascending=False)#Sort the data frame by the absolute weight column so that the most influential features come first\n",
    "    return metrics, topWeights.head(50).reset_index(drop=True)\n",
    " \n",
    " \n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d921d113-4d39-4d96-a441-4f3d0768eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Classification Metrics Over the 100 runs:\n",
      "  accuracy: 1.0\n",
      "  precision: 1.0\n",
      "  recall: 1.0\n",
      "  f1: 1.0\n",
      "\n",
      "15 gene(s) selected ≥ 80% of runs:\n",
      "  ENSG00000149380.12: 100.0%. Signs across the runs: (+)100 and (-)0\n",
      "  ENSG00000172061.9: 99.0%. Signs across the runs: (+)99 and (-)0\n",
      "  ENSG00000155886.11: 98.0%. Signs across the runs: (+)98 and (-)0\n",
      "  ENSG00000160161.9: 97.0%. Signs across the runs: (+)97 and (-)0\n",
      "  ENSG00000164932.13: 97.0%. Signs across the runs: (+)97 and (-)0\n",
      "  ENSG00000101463.6: 94.0%. Signs across the runs: (+)94 and (-)0\n",
      "  ENSG00000182492.16: 94.0%. Signs across the runs: (+)94 and (-)0\n",
      "  ENSG00000261327.5: 93.0%. Signs across the runs: (+)93 and (-)0\n",
      "  ENSG00000122641.11: 91.0%. Signs across the runs: (+)91 and (-)0\n",
      "  ENSG00000261039.3: 87.0%. Signs across the runs: (+)87 and (-)0\n",
      "  ENSG00000123500.10: 85.0%. Signs across the runs: (+)85 and (-)0\n",
      "  ENSG00000180044.5: 84.0%. Signs across the runs: (+)84 and (-)0\n",
      "  ENSG00000104415.14: 81.0%. Signs across the runs: (+)81 and (-)0\n",
      "  ENSG00000105664.11: 80.0%. Signs across the runs: (+)80 and (-)0\n",
      "  ENSG00000266995.1: 80.0%. Signs across the runs: (+)80 and (-)0\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "model=LogisticRegression(max_iter=1000)\n",
    "parameters={\n",
    "    \"model__C\":[0.1, 1],\n",
    "    \"model__penalty\":[\"l2\"],\n",
    "    \"model__solver\":[\"lbfgs\"],\n",
    "}\n",
    "#trainEvaluateModel(model, parameters)\n",
    "\n",
    "runs=100\n",
    "topGeneTally=Counter()\n",
    "signTally=defaultdict(Counter)\n",
    "totMetrics={\"accuracy\": 0, \"precision\": 0, \"recall\": 0, \"f1\": 0}\n",
    "for i in range(runs):\n",
    "    trainSetResample, trainClassesResample=resample(trainSet, trainClasses, replace=True, n_samples=int(0.8*len(trainClasses)), random_state=111+i)\n",
    "    metrics, topGenes=retrieveTopGenes(model, parameters, trainSetResample,trainClassesResample)\n",
    "    for _, row in topGenes.iterrows():\n",
    "        gene=row[\"Gene\"]\n",
    "        weight=row[\"Weight\"]\n",
    "        topGeneTally[gene]+=1\n",
    "        sign=\"+\" if weight>0 else \"-\"\n",
    "        signTally[gene][sign]+= 1\n",
    "    \n",
    "    for metric in metrics:\n",
    "        totMetrics[metric]+=metrics[metric]\n",
    "        \n",
    "geneFrequency={gene: topGeneTally[gene]/runs for gene in features.columns}\n",
    "#print(topGeneTally)\n",
    "#print(geneFrequency)\n",
    "consistentlySelectedGenes=sorted([gene for gene,frequency in geneFrequency.items() if frequency>=0.80], key=lambda gene: geneFrequency[gene], reverse=True)\n",
    "\n",
    "\n",
    "print(\"Average Classification Metrics Over the 100 runs:\")\n",
    "for metric in totMetrics:\n",
    "    print(f\"  {metric}: {totMetrics[metric]/runs}\")\n",
    "\n",
    "print(f\"\\n{len(consistentlySelectedGenes)} gene(s) selected ≥ 80% of runs:\")\n",
    "for gene in consistentlySelectedGenes:\n",
    "    rate=geneFrequency[gene]*100\n",
    "    print(f\"  {gene}: {rate}%. Signs across the runs: (+){signTally[gene][\"+\"]} and (-){signTally[gene][\"-\"]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d41e2-0327-4c6a-b80a-330c3574cc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
